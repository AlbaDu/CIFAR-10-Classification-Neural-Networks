{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alba 2nd model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37664bitbaseconda513a0352d0eb4c09a2aaf2386a53465e",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attempt 1: \n",
        "\n",
        "Construction of a Neural Network from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hblyrOe-JRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the required external libraries\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.applications import ResNet50V2\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Import functions defined in cifar_ten.py\n",
        "import cifar_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load of the dataset and transformation of the variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkWabIw--Kvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0bc30cdf-6307-4d31-ffec-6f11a8f3cf28"
      },
      "source": [
        "#Loading of the dataset\n",
        "(train_X, train_y), (test_X, test_y) = load_dataset()\n",
        "\n",
        "#Normalization of data from dataset\n",
        "train_X_norm = cifar_ten.data_norm(train_X)\n",
        "test_X_norm = cifar_ten.data_norm(test_X)\n",
        "\n",
        "#Label transformation to categorical\n",
        "train_y = cifar_ten.data_cat(train_y)\n",
        "test_y = cifar_ten.data_cat(test_y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Construction of the Neural Network, fitting and obtention of the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8mYM5UpWZYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99952b76-aa0c-4bf6-ea60-8849e71a2d8d"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding ='same', input_shape= train_X_norm.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Q8LFQ4_mSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "54520a6c-bc1e-4197-9044-68e420f238ad"
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr = 2e-5),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])\n",
        "\n",
        "history = model.fit(train_X_norm, train_y, \n",
        "                     epochs = 5, \n",
        "                     batch_size = 100, \n",
        "                     validation_data = (test_X_norm, test_y))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 473s 9ms/step - loss: 2.8620 - acc: 0.2297 - val_loss: 2.0513 - val_acc: 0.2953\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 468s 9ms/step - loss: 2.3615 - acc: 0.3169 - val_loss: 1.6652 - val_acc: 0.4331\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 467s 9ms/step - loss: 2.1426 - acc: 0.3581 - val_loss: 1.6093 - val_acc: 0.4450\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 468s 9ms/step - loss: 1.9893 - acc: 0.3876 - val_loss: 1.5352 - val_acc: 0.4740\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 486s 10ms/step - loss: 1.8625 - acc: 0.4130 - val_loss: 1.5239 - val_acc: 0.4783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-uUWxbJJ9wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}