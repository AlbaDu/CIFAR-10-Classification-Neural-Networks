{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alba_5th_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWrcyjN6m3Zt",
        "colab_type": "text"
      },
      "source": [
        "# MINI-\"KAGGEL\" COMPETITION WITHIN The Bridge\n",
        "Using the CIFAR-10 dataset and CNN and DNN let's try to get the maximun accuracy!! Leavin the test_data UNTOUCH is the only rule and we have 24 hours. Let's CODE!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE9YkV3dmwNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.applications import ResNet50\n",
        "from keras import models, layers, optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdG-jzYpm-tZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc918497-e0c8-4e1b-f2db-db375f6674bf"
      },
      "source": [
        "#load of the dataset\n",
        "(train_X, train_y), (test_X, test_y) = cifar10.load_data() \n",
        "\n",
        "#normalization of data from dataset\n",
        "train_X_norm = train_X.astype('float32')/ 255.0 \n",
        "test_X_norm = test_X.astype('float32')/ 255.0\n",
        "\n",
        "#we transform the labels to categoricals so we can work better with them\n",
        "train_y = to_categorical(train_y) \n",
        "test_y = to_categorical(test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1DE00HwnEV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "85773d99-fcfc-48e4-fc6d-91a62454888d"
      },
      "source": [
        "#import of VGG19 model\n",
        "net = ResNet50(weights = 'imagenet', \n",
        "            include_top = False, \n",
        "            input_shape = (32, 32, 3),)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZABaSLsnnOyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model7 = models.Sequential()\n",
        "model7.add(net)\n",
        "model7.add(layers.Flatten())\n",
        "model7.add(layers.Dense(100, activation = 'relu'))\n",
        "model7.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYm5MQfTsKxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "72842b73-6b10-471c-9472-52ef43580436"
      },
      "source": [
        "model7.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = \"rmsprop\",\n",
        "              metrics = ['acc'])\n",
        "\n",
        "model7.fit(train_X_norm, train_y, epochs = 10, batch_size = 100, validation_data = (test_X_norm, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 1.1957 - acc: 0.6136 - val_loss: 2.9784 - val_acc: 0.1222\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.8022 - acc: 0.7450 - val_loss: 3.1085 - val_acc: 0.4032\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.6583 - acc: 0.7918 - val_loss: 1.4688 - val_acc: 0.6801\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.5817 - acc: 0.8214 - val_loss: 1.2574 - val_acc: 0.7199\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.4749 - acc: 0.8489 - val_loss: 1.1418 - val_acc: 0.6918\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.4121 - acc: 0.8713 - val_loss: 0.8281 - val_acc: 0.7639\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.3685 - acc: 0.8863 - val_loss: 0.8099 - val_acc: 0.7689\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.3356 - acc: 0.8979 - val_loss: 1.0583 - val_acc: 0.7703\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.3036 - acc: 0.9096 - val_loss: 1.1233 - val_acc: 0.7481\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 72s 1ms/step - loss: 0.2622 - acc: 0.9176 - val_loss: 1.1473 - val_acc: 0.7623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fbb5aa9bf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmtgMvxGDkRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkrvldYXQeQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model8 = models.Sequential()\n",
        "model8.add(net)\n",
        "model8.add(layers.Flatten())\n",
        "model8.add(layers.Dense(100, activation = 'relu'))\n",
        "model8.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07d7XDTzDkcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( rotation_range=90,\n",
        "                 width_shift_range=0.1, height_shift_range=0.1,\n",
        "                 horizontal_flip=True)\n",
        "datagen.fit(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5p9V47pQP73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0fc66859-0757-4108-f6b6-c816168363e4"
      },
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model8.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "\n",
        "model8.fit_generator(datagen.flow(train_X, train_y, batch_size = 128),\\\n",
        "                    steps_per_epoch=train_X.shape[0] //128, epochs=125,\\\n",
        "                    verbose = 1,validation_data = (test_X,test_y), callbacks = [LearningRateScheduler(lr_schedule)])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "390/390 [==============================] - 82s 209ms/step - loss: 1.3873 - accuracy: 0.5495 - val_loss: 1.4303 - val_accuracy: 0.6202\n",
            "Epoch 2/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 1.0991 - accuracy: 0.6237 - val_loss: 1.2542 - val_accuracy: 0.6239\n",
            "Epoch 3/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 1.0114 - accuracy: 0.6548 - val_loss: 27.2689 - val_accuracy: 0.6610\n",
            "Epoch 4/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.9554 - accuracy: 0.6754 - val_loss: 4.8217 - val_accuracy: 0.6920\n",
            "Epoch 5/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.9265 - accuracy: 0.6858 - val_loss: 1.5220 - val_accuracy: 0.6002\n",
            "Epoch 6/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.9068 - accuracy: 0.6928 - val_loss: 0.8688 - val_accuracy: 0.7191\n",
            "Epoch 7/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.8766 - accuracy: 0.7042 - val_loss: 1.8304 - val_accuracy: 0.6596\n",
            "Epoch 8/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.8622 - accuracy: 0.7097 - val_loss: 0.9164 - val_accuracy: 0.7163\n",
            "Epoch 9/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.8712 - accuracy: 0.7058 - val_loss: 1.1496 - val_accuracy: 0.6354\n",
            "Epoch 10/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.8379 - accuracy: 0.7153 - val_loss: 1.6813 - val_accuracy: 0.6532\n",
            "Epoch 11/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.8205 - accuracy: 0.7193 - val_loss: 0.8686 - val_accuracy: 0.7109\n",
            "Epoch 12/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.8113 - accuracy: 0.7250 - val_loss: 1.3273 - val_accuracy: 0.6268\n",
            "Epoch 13/125\n",
            "390/390 [==============================] - 68s 175ms/step - loss: 0.7931 - accuracy: 0.7307 - val_loss: 2.3929 - val_accuracy: 0.6806\n",
            "Epoch 14/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.7915 - accuracy: 0.7340 - val_loss: 1.4181 - val_accuracy: 0.5788\n",
            "Epoch 15/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.7617 - accuracy: 0.7444 - val_loss: 1.4744 - val_accuracy: 0.7011\n",
            "Epoch 16/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.7570 - accuracy: 0.7440 - val_loss: 1.5936 - val_accuracy: 0.6953\n",
            "Epoch 17/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.7442 - accuracy: 0.7490 - val_loss: 1.0403 - val_accuracy: 0.7235\n",
            "Epoch 18/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.7495 - accuracy: 0.7459 - val_loss: 3.5018 - val_accuracy: 0.6660\n",
            "Epoch 19/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.7372 - accuracy: 0.7522 - val_loss: 0.9322 - val_accuracy: 0.7125\n",
            "Epoch 20/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.7264 - accuracy: 0.7547 - val_loss: 0.8525 - val_accuracy: 0.7303\n",
            "Epoch 21/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.7377 - accuracy: 0.7532 - val_loss: 1.5271 - val_accuracy: 0.5455\n",
            "Epoch 22/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.7539 - accuracy: 0.7487 - val_loss: 1.5945 - val_accuracy: 0.6881\n",
            "Epoch 23/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.7089 - accuracy: 0.7602 - val_loss: 48.5966 - val_accuracy: 0.6574\n",
            "Epoch 24/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.7028 - accuracy: 0.7623 - val_loss: 83.2424 - val_accuracy: 0.6791\n",
            "Epoch 25/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6869 - accuracy: 0.7693 - val_loss: 3.8843 - val_accuracy: 0.7084\n",
            "Epoch 26/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6959 - accuracy: 0.7677 - val_loss: 50.3237 - val_accuracy: 0.7244\n",
            "Epoch 27/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6797 - accuracy: 0.7728 - val_loss: 341.7827 - val_accuracy: 0.7057\n",
            "Epoch 28/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6661 - accuracy: 0.7744 - val_loss: 163.2644 - val_accuracy: 0.6621\n",
            "Epoch 29/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.6682 - accuracy: 0.7743 - val_loss: 14.9233 - val_accuracy: 0.7206\n",
            "Epoch 30/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6631 - accuracy: 0.7776 - val_loss: 8.1167 - val_accuracy: 0.6214\n",
            "Epoch 31/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6813 - accuracy: 0.7747 - val_loss: 2.5530 - val_accuracy: 0.7245\n",
            "Epoch 32/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.6697 - accuracy: 0.7783 - val_loss: 1.2691 - val_accuracy: 0.6972\n",
            "Epoch 33/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6668 - accuracy: 0.7794 - val_loss: 2.8342 - val_accuracy: 0.7139\n",
            "Epoch 34/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6541 - accuracy: 0.7811 - val_loss: 1.4611 - val_accuracy: 0.7293\n",
            "Epoch 35/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.6436 - accuracy: 0.7862 - val_loss: 5.7782 - val_accuracy: 0.7100\n",
            "Epoch 36/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6389 - accuracy: 0.7863 - val_loss: 0.9472 - val_accuracy: 0.7323\n",
            "Epoch 37/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6239 - accuracy: 0.7893 - val_loss: 1.8257 - val_accuracy: 0.6908\n",
            "Epoch 38/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.6467 - accuracy: 0.7883 - val_loss: 2.0470 - val_accuracy: 0.7131\n",
            "Epoch 39/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.6374 - accuracy: 0.7907 - val_loss: 9.7472 - val_accuracy: 0.6700\n",
            "Epoch 40/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6298 - accuracy: 0.7909 - val_loss: 1.8827 - val_accuracy: 0.6491\n",
            "Epoch 41/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6218 - accuracy: 0.7939 - val_loss: 8.7302 - val_accuracy: 0.7321\n",
            "Epoch 42/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6355 - accuracy: 0.7879 - val_loss: 10.7883 - val_accuracy: 0.7176\n",
            "Epoch 43/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.6251 - accuracy: 0.7944 - val_loss: 1.0512 - val_accuracy: 0.7122\n",
            "Epoch 44/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6061 - accuracy: 0.7982 - val_loss: 1.7752 - val_accuracy: 0.7362\n",
            "Epoch 45/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6238 - accuracy: 0.7939 - val_loss: 3.1408 - val_accuracy: 0.6446\n",
            "Epoch 46/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6122 - accuracy: 0.7943 - val_loss: 22.5488 - val_accuracy: 0.7334\n",
            "Epoch 47/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6112 - accuracy: 0.7963 - val_loss: 0.9807 - val_accuracy: 0.6995\n",
            "Epoch 48/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6009 - accuracy: 0.8017 - val_loss: 1.7355 - val_accuracy: 0.7413\n",
            "Epoch 49/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.6048 - accuracy: 0.7982 - val_loss: 232.1403 - val_accuracy: 0.6763\n",
            "Epoch 50/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6006 - accuracy: 0.8011 - val_loss: 26.5523 - val_accuracy: 0.7345\n",
            "Epoch 51/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.6157 - accuracy: 0.7981 - val_loss: 1.8172 - val_accuracy: 0.7308\n",
            "Epoch 52/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5898 - accuracy: 0.8051 - val_loss: 1.2914 - val_accuracy: 0.6917\n",
            "Epoch 53/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.6048 - accuracy: 0.8007 - val_loss: 46.3574 - val_accuracy: 0.6356\n",
            "Epoch 54/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5868 - accuracy: 0.8066 - val_loss: 17.7831 - val_accuracy: 0.7157\n",
            "Epoch 55/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5992 - accuracy: 0.8037 - val_loss: 23.2874 - val_accuracy: 0.7559\n",
            "Epoch 56/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.5700 - accuracy: 0.8077 - val_loss: 932.8876 - val_accuracy: 0.6290\n",
            "Epoch 57/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5942 - accuracy: 0.8075 - val_loss: 70.6005 - val_accuracy: 0.7659\n",
            "Epoch 58/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.6024 - accuracy: 0.8045 - val_loss: 54.0865 - val_accuracy: 0.7165\n",
            "Epoch 59/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5921 - accuracy: 0.8063 - val_loss: 67.9306 - val_accuracy: 0.7553\n",
            "Epoch 60/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.5849 - accuracy: 0.8058 - val_loss: 98.9661 - val_accuracy: 0.7719\n",
            "Epoch 61/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5909 - accuracy: 0.8081 - val_loss: 160.2692 - val_accuracy: 0.6798\n",
            "Epoch 62/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.5972 - accuracy: 0.8029 - val_loss: 139.5337 - val_accuracy: 0.7424\n",
            "Epoch 63/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.5659 - accuracy: 0.8149 - val_loss: 19.1566 - val_accuracy: 0.6303\n",
            "Epoch 64/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5616 - accuracy: 0.8149 - val_loss: 2.8862 - val_accuracy: 0.7433\n",
            "Epoch 65/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5529 - accuracy: 0.8172 - val_loss: 4.8615 - val_accuracy: 0.7363\n",
            "Epoch 66/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5992 - accuracy: 0.8092 - val_loss: 39.7848 - val_accuracy: 0.7247\n",
            "Epoch 67/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5441 - accuracy: 0.8159 - val_loss: 0.9210 - val_accuracy: 0.7690\n",
            "Epoch 68/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5869 - accuracy: 0.8138 - val_loss: 0.7626 - val_accuracy: 0.7703\n",
            "Epoch 69/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.5526 - accuracy: 0.8147 - val_loss: 70.8802 - val_accuracy: 0.7183\n",
            "Epoch 70/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.5660 - accuracy: 0.8176 - val_loss: 1.1680 - val_accuracy: 0.7062\n",
            "Epoch 71/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.5606 - accuracy: 0.8167 - val_loss: 3.6031 - val_accuracy: 0.6834\n",
            "Epoch 72/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.5782 - accuracy: 0.8096 - val_loss: 18.4740 - val_accuracy: 0.7097\n",
            "Epoch 73/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.5567 - accuracy: 0.8185 - val_loss: 2.0889 - val_accuracy: 0.6868\n",
            "Epoch 74/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.5441 - accuracy: 0.8201 - val_loss: 0.8308 - val_accuracy: 0.8028\n",
            "Epoch 75/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.5582 - accuracy: 0.8207 - val_loss: 50.1040 - val_accuracy: 0.7056\n",
            "Epoch 76/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.6142 - accuracy: 0.8111 - val_loss: 24.6524 - val_accuracy: 0.4639\n",
            "Epoch 77/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.5124 - accuracy: 0.8267 - val_loss: 83.1354 - val_accuracy: 0.7928\n",
            "Epoch 78/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.4752 - accuracy: 0.8400 - val_loss: 934.5287 - val_accuracy: 0.7173\n",
            "Epoch 79/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.4719 - accuracy: 0.8434 - val_loss: 10.6146 - val_accuracy: 0.7878\n",
            "Epoch 80/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.4592 - accuracy: 0.8459 - val_loss: 64.2799 - val_accuracy: 0.8141\n",
            "Epoch 81/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4466 - accuracy: 0.8467 - val_loss: 30.2366 - val_accuracy: 0.8050\n",
            "Epoch 82/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4507 - accuracy: 0.8492 - val_loss: 27.6403 - val_accuracy: 0.7841\n",
            "Epoch 83/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4481 - accuracy: 0.8492 - val_loss: 180.6604 - val_accuracy: 0.7488\n",
            "Epoch 84/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.4447 - accuracy: 0.8508 - val_loss: 26.6984 - val_accuracy: 0.7965\n",
            "Epoch 85/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.4374 - accuracy: 0.8522 - val_loss: 44.3910 - val_accuracy: 0.7799\n",
            "Epoch 86/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4310 - accuracy: 0.8544 - val_loss: 528.3995 - val_accuracy: 0.7795\n",
            "Epoch 87/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.4263 - accuracy: 0.8549 - val_loss: 50.6898 - val_accuracy: 0.7747\n",
            "Epoch 88/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4768 - accuracy: 0.8544 - val_loss: 96.4740 - val_accuracy: 0.7759\n",
            "Epoch 89/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4326 - accuracy: 0.8527 - val_loss: 22.9138 - val_accuracy: 0.7203\n",
            "Epoch 90/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4333 - accuracy: 0.8563 - val_loss: 51.0837 - val_accuracy: 0.7688\n",
            "Epoch 91/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.4413 - accuracy: 0.8552 - val_loss: 5.7187 - val_accuracy: 0.7722\n",
            "Epoch 92/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4375 - accuracy: 0.8582 - val_loss: 109.5692 - val_accuracy: 0.6975\n",
            "Epoch 93/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4396 - accuracy: 0.8579 - val_loss: 59.7097 - val_accuracy: 0.7816\n",
            "Epoch 94/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4151 - accuracy: 0.8604 - val_loss: 50.9939 - val_accuracy: 0.7703\n",
            "Epoch 95/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.4211 - accuracy: 0.8598 - val_loss: 10.3936 - val_accuracy: 0.7844\n",
            "Epoch 96/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.4101 - accuracy: 0.8611 - val_loss: 10.0398 - val_accuracy: 0.7618\n",
            "Epoch 97/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4112 - accuracy: 0.8631 - val_loss: 11.3050 - val_accuracy: 0.8164\n",
            "Epoch 98/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4738 - accuracy: 0.8597 - val_loss: 38.2900 - val_accuracy: 0.7344\n",
            "Epoch 99/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.4376 - accuracy: 0.8634 - val_loss: 2.3040 - val_accuracy: 0.8000\n",
            "Epoch 100/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4138 - accuracy: 0.8628 - val_loss: 162.6252 - val_accuracy: 0.7871\n",
            "Epoch 101/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3977 - accuracy: 0.8649 - val_loss: 266.6960 - val_accuracy: 0.7600\n",
            "Epoch 102/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.4325 - accuracy: 0.8676 - val_loss: 138.3247 - val_accuracy: 0.7870\n",
            "Epoch 103/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.4139 - accuracy: 0.8701 - val_loss: 148.3300 - val_accuracy: 0.7734\n",
            "Epoch 104/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3875 - accuracy: 0.8712 - val_loss: 3.3276 - val_accuracy: 0.8208\n",
            "Epoch 105/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3658 - accuracy: 0.8754 - val_loss: 1.3963 - val_accuracy: 0.7889\n",
            "Epoch 106/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3672 - accuracy: 0.8732 - val_loss: 36.3771 - val_accuracy: 0.7907\n",
            "Epoch 107/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3695 - accuracy: 0.8730 - val_loss: 24.4186 - val_accuracy: 0.8084\n",
            "Epoch 108/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.3677 - accuracy: 0.8750 - val_loss: 57.3699 - val_accuracy: 0.8005\n",
            "Epoch 109/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3566 - accuracy: 0.8774 - val_loss: 10.3310 - val_accuracy: 0.8091\n",
            "Epoch 110/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3719 - accuracy: 0.8771 - val_loss: 7.6396 - val_accuracy: 0.8120\n",
            "Epoch 111/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3592 - accuracy: 0.8767 - val_loss: 30.9850 - val_accuracy: 0.7663\n",
            "Epoch 112/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3565 - accuracy: 0.8786 - val_loss: 281.5560 - val_accuracy: 0.7576\n",
            "Epoch 113/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3748 - accuracy: 0.8785 - val_loss: 43.0460 - val_accuracy: 0.7976\n",
            "Epoch 114/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3558 - accuracy: 0.8786 - val_loss: 243.0574 - val_accuracy: 0.7679\n",
            "Epoch 115/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3519 - accuracy: 0.8794 - val_loss: 4.5317 - val_accuracy: 0.7754\n",
            "Epoch 116/125\n",
            "390/390 [==============================] - 68s 173ms/step - loss: 0.3523 - accuracy: 0.8832 - val_loss: 40.7421 - val_accuracy: 0.7751\n",
            "Epoch 117/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3695 - accuracy: 0.8780 - val_loss: 40.8596 - val_accuracy: 0.7907\n",
            "Epoch 118/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3480 - accuracy: 0.8800 - val_loss: 543.5297 - val_accuracy: 0.7709\n",
            "Epoch 119/125\n",
            "390/390 [==============================] - 67s 173ms/step - loss: 0.3414 - accuracy: 0.8829 - val_loss: 324.6953 - val_accuracy: 0.7585\n",
            "Epoch 120/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.3457 - accuracy: 0.8823 - val_loss: 213.2046 - val_accuracy: 0.7734\n",
            "Epoch 121/125\n",
            "390/390 [==============================] - 67s 172ms/step - loss: 0.3374 - accuracy: 0.8827 - val_loss: 367.5312 - val_accuracy: 0.7880\n",
            "Epoch 122/125\n",
            "390/390 [==============================] - 71s 181ms/step - loss: 0.3728 - accuracy: 0.8809 - val_loss: 1088.6237 - val_accuracy: 0.7709\n",
            "Epoch 123/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.3611 - accuracy: 0.8834 - val_loss: 1067.2349 - val_accuracy: 0.7911\n",
            "Epoch 124/125\n",
            "390/390 [==============================] - 68s 175ms/step - loss: 0.3406 - accuracy: 0.8829 - val_loss: 1174.7249 - val_accuracy: 0.7611\n",
            "Epoch 125/125\n",
            "390/390 [==============================] - 68s 174ms/step - loss: 0.3636 - accuracy: 0.8840 - val_loss: 686.4154 - val_accuracy: 0.7668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fb991a9bf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}